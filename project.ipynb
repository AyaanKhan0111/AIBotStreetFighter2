{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f21a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "df1 = pd.read_csv('game_data.csv')\n",
    "df2 = pd.read_csv('game_data_afnan.csv')\n",
    "df3 = pd.read_csv('game_data_combined_ahmed.csv')\n",
    "\n",
    "# Concatenate the DataFrames and remove duplicates\n",
    "df_combined = pd.concat([df1, df2, df3], ignore_index=True).drop_duplicates()\n",
    "\n",
    "# Save the combined dataset\n",
    "df_combined.to_csv('game_data_merged.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9391f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "df=pd.read_csv('game_data_merged.csv')\n",
    "# Define features and labels\n",
    "features = [\n",
    "    'timer',\n",
    "    'p1_id', 'p1_health', 'p1_x', 'p1_y', 'p1_jumping', 'p1_crouching', 'p1_in_move', 'p1_move_id',\n",
    "    'p2_id', 'p2_health', 'p2_x', 'p2_y', 'p2_jumping', 'p2_crouching', 'p2_in_move', 'p2_move_id'\n",
    "]\n",
    "labels = [\n",
    "    'p1_btn_up', 'p1_btn_down', 'p1_btn_right', 'p1_btn_left',\n",
    "    'p1_btn_Y', 'p1_btn_B', 'p1_btn_X', 'p1_btn_A', 'p1_btn_L', 'p1_btn_R'\n",
    "]\n",
    "\n",
    "# Convert boolean columns to integers\n",
    "bool_columns = ['p1_jumping', 'p1_crouching', 'p1_in_move', 'p2_jumping', 'p2_crouching', 'p2_in_move']\n",
    "df[bool_columns] = df[bool_columns].astype(int)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X = df[features]\n",
    "y = df[labels]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccdfe58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.1518 - loss: 2.7030 - val_accuracy: 0.1550 - val_loss: 0.6435\n",
      "Epoch 2/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.1487 - loss: 0.5731 - val_accuracy: 0.1550 - val_loss: 0.4606\n",
      "Epoch 3/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.1475 - loss: 0.4765 - val_accuracy: 0.1975 - val_loss: 0.4317\n",
      "Epoch 4/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.1743 - loss: 0.4196 - val_accuracy: 0.1500 - val_loss: 0.4170\n",
      "Epoch 5/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.1715 - loss: 0.4251 - val_accuracy: 0.1850 - val_loss: 0.3998\n",
      "Epoch 6/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.1808 - loss: 0.3939 - val_accuracy: 0.1750 - val_loss: 0.3819\n",
      "Epoch 7/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.1782 - loss: 0.3764 - val_accuracy: 0.1675 - val_loss: 0.3847\n",
      "Epoch 8/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.1674 - loss: 0.3752 - val_accuracy: 0.1200 - val_loss: 0.3821\n",
      "Epoch 9/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.1791 - loss: 0.3616 - val_accuracy: 0.1925 - val_loss: 0.4218\n",
      "Epoch 10/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.1914 - loss: 0.3695 - val_accuracy: 0.1400 - val_loss: 0.3806\n",
      "Epoch 11/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.1903 - loss: 0.3554 - val_accuracy: 0.2250 - val_loss: 0.3761\n",
      "Epoch 12/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.1996 - loss: 0.3587 - val_accuracy: 0.1325 - val_loss: 0.4000\n",
      "Epoch 13/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.1996 - loss: 0.3595 - val_accuracy: 0.2175 - val_loss: 0.4101\n",
      "Epoch 14/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.1811 - loss: 0.3673 - val_accuracy: 0.2175 - val_loss: 0.3904\n",
      "Epoch 15/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.1994 - loss: 0.3488 - val_accuracy: 0.1450 - val_loss: 0.3833\n",
      "Epoch 16/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.2084 - loss: 0.3532 - val_accuracy: 0.1475 - val_loss: 0.3908\n",
      "Epoch 17/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.2096 - loss: 0.3498 - val_accuracy: 0.1400 - val_loss: 0.3837\n",
      "Epoch 18/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2027 - loss: 0.3520 - val_accuracy: 0.2100 - val_loss: 0.3714\n",
      "Epoch 19/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2210 - loss: 0.3377 - val_accuracy: 0.1350 - val_loss: 0.3843\n",
      "Epoch 20/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.2057 - loss: 0.3338 - val_accuracy: 0.1750 - val_loss: 0.3663\n",
      "Epoch 21/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2080 - loss: 0.3380 - val_accuracy: 0.1550 - val_loss: 0.3726\n",
      "Epoch 22/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.2231 - loss: 0.3359 - val_accuracy: 0.2325 - val_loss: 0.3742\n",
      "Epoch 23/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2114 - loss: 0.3359 - val_accuracy: 0.2375 - val_loss: 0.3760\n",
      "Epoch 24/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2170 - loss: 0.3320 - val_accuracy: 0.1925 - val_loss: 0.3670\n",
      "Epoch 25/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.2131 - loss: 0.3353 - val_accuracy: 0.1700 - val_loss: 0.3570\n",
      "Epoch 26/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.2332 - loss: 0.3277 - val_accuracy: 0.2200 - val_loss: 0.4047\n",
      "Epoch 27/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.2116 - loss: 0.3437 - val_accuracy: 0.1375 - val_loss: 0.3661\n",
      "Epoch 28/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2176 - loss: 0.3245 - val_accuracy: 0.1525 - val_loss: 0.3769\n",
      "Epoch 29/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.2052 - loss: 0.3303 - val_accuracy: 0.2125 - val_loss: 0.3577\n",
      "Epoch 30/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.2191 - loss: 0.3330 - val_accuracy: 0.2100 - val_loss: 0.3712\n",
      "Epoch 31/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2263 - loss: 0.3257 - val_accuracy: 0.2100 - val_loss: 0.3703\n",
      "Epoch 32/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2130 - loss: 0.3375 - val_accuracy: 0.1200 - val_loss: 0.3608\n",
      "Epoch 33/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2169 - loss: 0.3215 - val_accuracy: 0.1975 - val_loss: 0.3536\n",
      "Epoch 34/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.2331 - loss: 0.3270 - val_accuracy: 0.2150 - val_loss: 0.3612\n",
      "Epoch 35/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2481 - loss: 0.3221 - val_accuracy: 0.2225 - val_loss: 0.3604\n",
      "Epoch 36/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.2299 - loss: 0.3259 - val_accuracy: 0.2150 - val_loss: 0.3558\n",
      "Epoch 37/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2248 - loss: 0.3248 - val_accuracy: 0.1925 - val_loss: 0.3541\n",
      "Epoch 38/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.2314 - loss: 0.3144 - val_accuracy: 0.1925 - val_loss: 0.3509\n",
      "Epoch 39/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.2371 - loss: 0.3174 - val_accuracy: 0.2175 - val_loss: 0.3560\n",
      "Epoch 40/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.2398 - loss: 0.3265 - val_accuracy: 0.2900 - val_loss: 0.3714\n",
      "Epoch 41/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.2342 - loss: 0.3227 - val_accuracy: 0.2050 - val_loss: 0.3543\n",
      "Epoch 42/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.2268 - loss: 0.3205 - val_accuracy: 0.2600 - val_loss: 0.3566\n",
      "Epoch 43/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.2386 - loss: 0.3188 - val_accuracy: 0.2425 - val_loss: 0.3599\n",
      "Epoch 44/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2420 - loss: 0.3141 - val_accuracy: 0.2125 - val_loss: 0.3568\n",
      "Epoch 45/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2546 - loss: 0.3192 - val_accuracy: 0.2350 - val_loss: 0.3697\n",
      "Epoch 46/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.2522 - loss: 0.3212 - val_accuracy: 0.2175 - val_loss: 0.3519\n",
      "Epoch 47/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2395 - loss: 0.3140 - val_accuracy: 0.2000 - val_loss: 0.3508\n",
      "Epoch 48/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2492 - loss: 0.3110 - val_accuracy: 0.2250 - val_loss: 0.3583\n",
      "Epoch 49/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2508 - loss: 0.3097 - val_accuracy: 0.2400 - val_loss: 0.3596\n",
      "Epoch 50/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2484 - loss: 0.3134 - val_accuracy: 0.2000 - val_loss: 0.3529\n",
      "Epoch 51/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2451 - loss: 0.3147 - val_accuracy: 0.2150 - val_loss: 0.3567\n",
      "Epoch 52/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2299 - loss: 0.3155 - val_accuracy: 0.1475 - val_loss: 0.3627\n",
      "Epoch 53/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2209 - loss: 0.3140 - val_accuracy: 0.1950 - val_loss: 0.3530\n",
      "Epoch 54/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2502 - loss: 0.3092 - val_accuracy: 0.2225 - val_loss: 0.3536\n",
      "Epoch 55/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.2498 - loss: 0.3060 - val_accuracy: 0.2175 - val_loss: 0.3502\n",
      "Epoch 56/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.2434 - loss: 0.3062 - val_accuracy: 0.2125 - val_loss: 0.3566\n",
      "Epoch 57/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.2447 - loss: 0.3090 - val_accuracy: 0.2300 - val_loss: 0.3615\n",
      "Epoch 58/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2642 - loss: 0.3135 - val_accuracy: 0.2075 - val_loss: 0.3572\n",
      "Epoch 59/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2479 - loss: 0.3040 - val_accuracy: 0.2175 - val_loss: 0.3586\n",
      "Epoch 60/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2399 - loss: 0.3066 - val_accuracy: 0.2300 - val_loss: 0.3627\n",
      "Epoch 61/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2558 - loss: 0.3018 - val_accuracy: 0.1900 - val_loss: 0.3552\n",
      "Epoch 62/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.2441 - loss: 0.3007 - val_accuracy: 0.1675 - val_loss: 0.3560\n",
      "Epoch 63/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.2403 - loss: 0.3034 - val_accuracy: 0.1750 - val_loss: 0.3605\n",
      "Epoch 64/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2543 - loss: 0.3104 - val_accuracy: 0.2075 - val_loss: 0.3622\n",
      "Epoch 65/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2535 - loss: 0.3065 - val_accuracy: 0.1625 - val_loss: 0.3638\n",
      "Epoch 66/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2486 - loss: 0.3009 - val_accuracy: 0.2225 - val_loss: 0.3666\n",
      "Epoch 67/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2636 - loss: 0.3062 - val_accuracy: 0.1775 - val_loss: 0.3627\n",
      "Epoch 68/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2578 - loss: 0.3060 - val_accuracy: 0.1550 - val_loss: 0.3680\n",
      "Epoch 69/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.2645 - loss: 0.3006 - val_accuracy: 0.1850 - val_loss: 0.3617\n",
      "Epoch 70/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2580 - loss: 0.2967 - val_accuracy: 0.2175 - val_loss: 0.3566\n",
      "Epoch 71/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.2629 - loss: 0.3056 - val_accuracy: 0.1675 - val_loss: 0.3601\n",
      "Epoch 72/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2640 - loss: 0.2926 - val_accuracy: 0.2200 - val_loss: 0.3674\n",
      "Epoch 73/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2682 - loss: 0.2989 - val_accuracy: 0.2375 - val_loss: 0.3670\n",
      "Epoch 74/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2621 - loss: 0.3008 - val_accuracy: 0.2225 - val_loss: 0.3666\n",
      "Epoch 75/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.2694 - loss: 0.2986 - val_accuracy: 0.1800 - val_loss: 0.3705\n",
      "Epoch 76/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2434 - loss: 0.2989 - val_accuracy: 0.2000 - val_loss: 0.3626\n",
      "Epoch 77/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2778 - loss: 0.2958 - val_accuracy: 0.1825 - val_loss: 0.3699\n",
      "Epoch 78/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.2644 - loss: 0.2937 - val_accuracy: 0.1950 - val_loss: 0.3673\n",
      "Epoch 79/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.2582 - loss: 0.2901 - val_accuracy: 0.1775 - val_loss: 0.3653\n",
      "Epoch 80/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2659 - loss: 0.3006 - val_accuracy: 0.1975 - val_loss: 0.3732\n",
      "Epoch 81/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2647 - loss: 0.2941 - val_accuracy: 0.2475 - val_loss: 0.3710\n",
      "Epoch 82/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2789 - loss: 0.2914 - val_accuracy: 0.1475 - val_loss: 0.3737\n",
      "Epoch 83/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.2664 - loss: 0.2983 - val_accuracy: 0.2150 - val_loss: 0.3689\n",
      "Epoch 84/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.2594 - loss: 0.2967 - val_accuracy: 0.1950 - val_loss: 0.3733\n",
      "Epoch 85/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2620 - loss: 0.3000 - val_accuracy: 0.2200 - val_loss: 0.3704\n",
      "Epoch 86/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.2715 - loss: 0.2936 - val_accuracy: 0.2175 - val_loss: 0.3772\n",
      "Epoch 87/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2980 - loss: 0.2932 - val_accuracy: 0.1400 - val_loss: 0.3764\n",
      "Epoch 88/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.2578 - loss: 0.2924 - val_accuracy: 0.1600 - val_loss: 0.3774\n",
      "Epoch 89/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2660 - loss: 0.2899 - val_accuracy: 0.2425 - val_loss: 0.3824\n",
      "Epoch 90/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2690 - loss: 0.2917 - val_accuracy: 0.2025 - val_loss: 0.3693\n",
      "Epoch 91/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2619 - loss: 0.2923 - val_accuracy: 0.1475 - val_loss: 0.3862\n",
      "Epoch 92/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2598 - loss: 0.2913 - val_accuracy: 0.2050 - val_loss: 0.3803\n",
      "Epoch 93/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2781 - loss: 0.2865 - val_accuracy: 0.1550 - val_loss: 0.3839\n",
      "Epoch 94/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2592 - loss: 0.2879 - val_accuracy: 0.1700 - val_loss: 0.3817\n",
      "Epoch 95/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.2604 - loss: 0.2861 - val_accuracy: 0.1600 - val_loss: 0.3845\n",
      "Epoch 96/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2784 - loss: 0.2914 - val_accuracy: 0.1925 - val_loss: 0.3856\n",
      "Epoch 97/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.2849 - loss: 0.2902 - val_accuracy: 0.1750 - val_loss: 0.3965\n",
      "Epoch 98/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2521 - loss: 0.2872 - val_accuracy: 0.1750 - val_loss: 0.3858\n",
      "Epoch 99/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2767 - loss: 0.2858 - val_accuracy: 0.2125 - val_loss: 0.3884\n",
      "Epoch 100/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.2696 - loss: 0.2882 - val_accuracy: 0.1975 - val_loss: 0.3891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to model.h5\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Define the model architecture\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=(len(features),)),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(len(labels), activation='sigmoid')  # For multi-label classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# … after model.fit(...)\n",
    "model.save('bot_model.h5')\n",
    "print(\"Model saved to bot_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2aebea43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p1_btn_up: 2374 positives (4.3%)\n",
      "p1_btn_down: 16824 positives (30.4%)\n",
      "p1_btn_right: 12666 positives (22.9%)\n",
      "p1_btn_left: 11834 positives (21.4%)\n",
      "p1_btn_Y: 5191 positives (9.4%)\n",
      "p1_btn_B: 2374 positives (4.3%)\n",
      "p1_btn_X: 0 positives (0.0%)\n",
      "p1_btn_A: 0 positives (0.0%)\n",
      "p1_btn_L: 0 positives (0.0%)\n",
      "p1_btn_R: 1931 positives (3.5%)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('game_data_merged.csv')\n",
    "labels = [\n",
    "    'p1_btn_up','p1_btn_down','p1_btn_right','p1_btn_left',\n",
    "    'p1_btn_Y','p1_btn_B','p1_btn_X','p1_btn_A','p1_btn_L','p1_btn_R'\n",
    "]\n",
    "\n",
    "for lbl in labels:\n",
    "    ones = df[lbl].sum()\n",
    "    total = len(df)\n",
    "    print(f\"{lbl}: {ones} positives ({ones/total:.1%})\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
